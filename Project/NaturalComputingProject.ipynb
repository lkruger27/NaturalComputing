{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb439d9",
   "metadata": {},
   "source": [
    "# Project Natural Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b361494-ef60-4587-bc91-de57be2a2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a96c5bd-54d9-47b9-a0ad-c3b764e2cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(mat):\n",
    "    return mat * (mat > 0)\n",
    "\n",
    "def Sigmoid(mat):\n",
    "    return 1/(1 + np.exp(-mat))\n",
    "\n",
    "def SoftMax(mat):\n",
    "    exp_mat = np.exp(mat)\n",
    "    return exp_mat/np.sum(exp_mat, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c467a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, node_seq, activation_functions, Xavier = True):\n",
    "        self.node_seq = node_seq\n",
    "        self.num_layers = len(node_seq) - 1\n",
    "        self.activation = activation_functions\n",
    "        self.weight_mats = []\n",
    "        self.bias_vecs = []\n",
    "        self.fitness = 0\n",
    "        for idx in range(self.num_layers):\n",
    "            n_in = node_seq[idx]\n",
    "            n_out = node_seq[idx + 1]\n",
    "              # use Xavier initialization\n",
    "            bound = np.sqrt(6/(n_in + n_out))\n",
    "            if Xavier:\n",
    "                self.weight_mats.append(np.random.uniform(-bound, bound, size = (n_in, n_out)))\n",
    "            else: \n",
    "                self.weight_mats.append(np.zeros((n_in, n_out)))\n",
    "            self.bias_vecs.append(np.zeros(n_out))\n",
    "            \n",
    "    def forward(self, samples):\n",
    "        # note: give inputs in the form (samples, features)\n",
    "        for idx in range(self.num_layers):\n",
    "            samples = self.activation[idx](samples @ self.weight_mats[idx] + self.bias_vecs[idx])\n",
    "        return samples\n",
    "        \n",
    "#net = Network([2,2,2], [ReLU, SoftMax])\n",
    "#net.forward(np.array([[0,0], [0,1], [1,0], [1,1]]))[range(4), [1,0,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "986a754c-ae68-456e-a5ff-c6f694f05ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_fitness(correct, predict):\n",
    "    return np.sum(-np.log(predict[range(predict.shape[0]), correct]))\n",
    "\n",
    "def xor_fitness(net, seq_len = 14):\n",
    "    inputs = [[(num >> idx) % 2 for idx in range(seq_len)] for num in range(2**seq_len)]\n",
    "    correct = [sum(seq) % 2 for seq in inputs]\n",
    "    predict = net.forward(inputs)\n",
    "    return cross_entropy_fitness(correct, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a71c31bb-4aa0-4682-932a-aa64c95a83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_minimax(net1, net2):\n",
    "    node_seq = net1.node_seq\n",
    "    activation = net1.activation\n",
    "    new_net1 = Network(node_seq, activation, Xavier = False)\n",
    "    new_net2 = Network(node_seq, activation, Xavier = False)\n",
    "    for idx in range(net1.num_layers): #perhaps random choice, instead of one net all minima and one net all maxima\n",
    "        new_net1.weight_mats[idx] = np.minimum(net1.weight_mats[idx], net2.weight_mats[idx])\n",
    "        new_net2.weight_mats[idx] = np.maximum(net1.weight_mats[idx], net2.weight_mats[idx])\n",
    "        new_net1.bias_vecs[idx] = np.minimum(net1.bias_vecs[idx], net2.bias_vecs[idx])\n",
    "        new_net2.bias_vecs[idx] = np.maximum(net1.bias_vecs[idx], net2.bias_vecs[idx])\n",
    "    return new_net1, new_net2\n",
    "    \n",
    "def crossover_layer(net1, net2):\n",
    "    node_seq = net1.node_seq\n",
    "    activation = net1.activation\n",
    "    new_net1 = Network(node_seq, activation, Xavier = False)\n",
    "    new_net2 = Network(node_seq, activation, Xavier = False)\n",
    "    select_layers = np.random.uniform(size = net1.num_layers)\n",
    "    for idx in range(net1.num_layers): \n",
    "        if select_layers[idx] < 0.5:\n",
    "            new_net1.weight_mats[idx] = net1.weight_mats[idx]\n",
    "            new_net2.weight_mats[idx] = net2.weight_mats[idx]\n",
    "            new_net1.bias_vecs[idx] = net1.bias_vecs[idx]\n",
    "            new_net2.bias_vecs[idx] = net2.bias_vecs[idx]\n",
    "        else:\n",
    "            new_net1.weight_mats[idx] = net2.weight_mats[idx]\n",
    "            new_net2.weight_mats[idx] = net1.weight_mats[idx]\n",
    "            new_net1.bias_vecs[idx] = net2.bias_vecs[idx]\n",
    "            new_net2.bias_vecs[idx] = net1.bias_vecs[idx]\n",
    "    return new_net1, new_net2\n",
    "    \n",
    "def mut_layer(net):\n",
    "    mut_size = np.random.uniform()\n",
    "    select_layers = np.random.uniform(size = net.num_layers)\n",
    "    for idx in range(net.num_layers): \n",
    "        if select_layers[idx] < 0.5:\n",
    "            n_in = net.node_seq[idx]\n",
    "            n_out = net.node_seq[idx + 1]\n",
    "            bound = np.sqrt(6/(n_in + n_out)) * mut_size\n",
    "            net.weight_mats[idx] += np.random.uniform(-bound, bound, size = (n_in, n_out))\n",
    "            net.bias_vecs[idx] += np.random.uniform(-bound, bound, size = n_out)\n",
    "\n",
    "def mut_index(net):\n",
    "    mut_size = np.random.uniform()\n",
    "    idx = int(np.random.choice(net.num_layers, 1))\n",
    "    n_in = net.node_seq[idx]\n",
    "    n_out = net.node_seq[idx + 1]\n",
    "    idx2 = int(np.random.choice(n_in, 1))\n",
    "    idx3 = int(np.random.choice(n_out, 1))\n",
    "    bound = np.sqrt(6/(n_in + n_out)) * mut_size\n",
    "    net.weight_mats[idx][idx2][idx3] += np.random.uniform(-bound, bound, size = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa06f640-95ac-431a-b645-035c61b1ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genetic:\n",
    "    def __init__(self, pop_size, node_seq, activation_functions, fitness_function, \n",
    "                 mutation_functions, mutation_probabilities, \n",
    "                 crossover_functions, crossover_probabilities, elite):\n",
    "        self.net_list = []\n",
    "        self.pop_size = pop_size\n",
    "        for idx in range(pop_size):\n",
    "            self.net_list.append(Network(node_seq, activation_functions))\n",
    "        \n",
    "        self.fitness_func = fitness_function\n",
    "        self.mutation_func = mutation_functions\n",
    "        self.mutation_threshold = np.cumsum(mutation_probabilities)\n",
    "        self.crossover_func = crossover_functions\n",
    "        self.crossover_threshold = np.cumsum(crossover_probabilities)\n",
    "        self.elite = elite\n",
    "        self.current_best_fitness = 0\n",
    "        \n",
    "    def next_generation(self):\n",
    "        new_net_idx = np.random.permutation(self.pop_size)\n",
    "        new_net_list = [deepcopy(self.net_list[idx]) for idx in new_net_idx]\n",
    "        \n",
    "        select_mutate = np.random.uniform(size=self.pop_size)\n",
    "        for idx in range(self.pop_size):\n",
    "            for mut_idx in range(len(self.mutation_func)):\n",
    "                if select_mutate[idx] < self.mutation_threshold[mut_idx]:\n",
    "                    self.mutation_func[mut_idx](new_net_list[idx])\n",
    "                    break\n",
    "                    \n",
    "        cross_net_idx = np.random.permutation(self.pop_size)\n",
    "        cross_net_list = [deepcopy(self.net_list[idx]) for idx in cross_net_idx]\n",
    "        select_cross = np.random.uniform(size = self.pop_size)\n",
    "        for idx in range(self.pop_size//2):\n",
    "            for cross_idx in range(len(self.crossover_func)):\n",
    "                if select_cross[idx] < self.crossover_threshold[cross_idx]:\n",
    "                    cross_net_list[2*idx], cross_net_list[2*idx + 1] =  \\\n",
    "                      self.crossover_func[cross_idx](cross_net_list[2*idx], \\\n",
    "                                                     cross_net_list[2*idx + 1])\n",
    "                    \n",
    "        new_net_list.extend(cross_net_list)\n",
    "        new_net_list.extend(self.net_list)\n",
    "        for net in new_net_list:\n",
    "            net.fitness = self.fitness_func(net)\n",
    "        \n",
    "        new_net_list.sort(key = lambda x: -x.fitness)\n",
    "        fitnesses = [net.fitness for net in new_net_list]\n",
    "        probabilities = fitnesses / np.sum(fitnesses)\n",
    "        net_idx = np.random.choice(len(new_net_list), self.pop_size - self.elite, p = probabilities)\n",
    "        self.net_list = [new_net_list[idx] for idx in net_idx]\n",
    "        self.net_list.extend(new_net_list[:self.elite])\n",
    "\n",
    "        self.net_list.sort(key = lambda x: -x.fitness)\n",
    "        if self.net_list[0].fitness > 0.0001 + self.current_best_fitness:\n",
    "            print(self.net_list[0].fitness)\n",
    "            self.current_best_fitness = self.net_list[0].fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3d4e268-6e92-4743-abb5-073e74c70304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28034.926310809064\n",
      "40441.62457727395\n",
      "43336.95571340926\n",
      "47500.85678010655\n",
      "51798.57479017901\n",
      "63652.27755736944\n",
      "70392.58394014832\n",
      "103971.85084116379\n",
      "114614.67225387042\n",
      "162412.05077364118\n",
      "163075.88292148287\n",
      "203100.2403345782\n",
      "209744.15412422456\n",
      "215959.7327663338\n",
      "269872.8617024006\n",
      "356118.00888574624\n",
      "405224.99168756395\n",
      "407223.0736600135\n",
      "437115.6456882154\n",
      "465986.0683736739\n"
     ]
    }
   ],
   "source": [
    "genetic_algo = Genetic(20, [14, 4, 2], [ReLU, SoftMax], xor_fitness, [mut_layer, mut_index], [0.5, 0.5], [crossover_minimax, crossover_layer], [0.5, 0.5], 1)\n",
    "for gen in range(20):\n",
    "    genetic_algo.next_generation()\n",
    "opt_net = genetic_algo.net_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e1a4a-8a17-474d-befc-0bbc8b6da462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880838fd-a0fb-42f7-ace9-b55e9d4656a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb439d9",
   "metadata": {},
   "source": [
    "# Project Natural Computing\n",
    "\n",
    "First we add some imports that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b361494-ef60-4587-bc91-de57be2a2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e09fd",
   "metadata": {},
   "source": [
    "Next, we define the activation functions. There is a choice between ReLU, Sigmoid and SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a96c5bd-54d9-47b9-a0ad-c3b764e2cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(mat, gradient = False):\n",
    "    if gradient:\n",
    "        return mat * (mat > 0), 1 * (mat > 0)\n",
    "    return mat * (mat > 0)\n",
    "\n",
    "def Sigmoid(mat, gradient = False):\n",
    "    sigm = 1/(1 + np.exp(-mat))\n",
    "    if gradient:\n",
    "        return sigm, sigm * (1 - sigm)\n",
    "    return sigm\n",
    "\n",
    "def SoftMax(mat, gradient = False):\n",
    "    exp_mat = np.exp(mat - np.max(mat, axis = 1, keepdims = True))\n",
    "    res_mat =  exp_mat/np.sum(exp_mat, axis = 1, keepdims = True)\n",
    "    if gradient:\n",
    "        return res_mat, res_mat * (1 - res_mat)\n",
    "    return res_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a58efc",
   "metadata": {},
   "source": [
    "Next, we have a network class which contains the number of layer, activation function, weights, biases and current fitness.\n",
    "\n",
    "The forward function pushes the samples through the current network and returns the return values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c467a5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.45359412, 0.54640588],\n",
       "       [0.23567485, 0.76432515],\n",
       "       [0.20380192, 0.79619808]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network:\n",
    "    def __init__(self, node_seq, activation_functions, Xavier = True):\n",
    "        self.node_seq = node_seq\n",
    "        self.num_layers = len(node_seq) - 1\n",
    "        self.activation = activation_functions\n",
    "        self.weight_mats = []\n",
    "        self.bias_vecs = []\n",
    "        self.fitness = 0\n",
    "        self.weight_mats_gradient = []\n",
    "        self.bias_vecs_gradient = []\n",
    "        for idx in range(self.num_layers):\n",
    "            n_in = node_seq[idx]\n",
    "            n_out = node_seq[idx + 1]\n",
    "              # use Xavier initialization\n",
    "            bound = np.sqrt(6/(n_in + n_out))\n",
    "            if Xavier:\n",
    "                self.weight_mats.append(np.random.uniform(-bound, bound, size = (n_in, n_out)))\n",
    "            else: \n",
    "                self.weight_mats.append(np.zeros((n_in, n_out)))\n",
    "            self.bias_vecs.append(np.zeros(n_out))\n",
    "            self.weight_mats_gradient.append(np.zeros((n_in, n_out)))\n",
    "            self.bias_vecs_gradient.append(np.zeros(n_out))\n",
    "            \n",
    "            \n",
    "    def forward(self, samples, gradient = False):\n",
    "        # note: give inputs in the form (samples, features)\n",
    "        if not gradient:\n",
    "            for idx in range(self.num_layers):\n",
    "                samples = self.activation[idx](samples @ self.weight_mats[idx] + self.bias_vecs[idx])\n",
    "            return samples\n",
    "    \n",
    "        n_samples = samples.shape[0]\n",
    "        sample_list = [samples]\n",
    "        current_sample = samples\n",
    "        gradient_list = []\n",
    "        layer_gradient = []\n",
    "          \n",
    "          # forward step\n",
    "        for idx in range(self.num_layers):\n",
    "            current_sample, current_gradient = self.activation[idx](current_sample @ \n",
    "                     self.weight_mats[idx] + self.bias_vecs[idx], gradient = True)\n",
    "            gradient_list.append(current_gradient)\n",
    "            sample_list.append(current_sample)\n",
    "            n_in = self.node_seq[idx]\n",
    "            n_out = self.node_seq[idx + 1]\n",
    "            layer_gradient.append(np.zeros((n_samples, n_in)))\n",
    "        \n",
    "          # backward step\n",
    "        layer_gradient.append(2*sample_list[self.num_layers])\n",
    "        for idx in range(self.num_layers - 1, -1, -1):\n",
    "            self.weight_mats_gradient[idx] = sample_list[idx].T @ layer_gradient[idx + 1]\n",
    "            self.bias_vecs_gradient[idx] = np.ones(n_samples).T @ layer_gradient[idx + 1]\n",
    "            layer_gradient[idx] = (layer_gradient[idx + 1] * gradient_list[idx]) @ self.weight_mats[idx].T \n",
    "        \n",
    "        return current_sample\n",
    "        \n",
    "        \n",
    "net = Network([2,2,2], [ReLU, SoftMax])\n",
    "net.forward(np.array([[0,0], [0,1], [1,0], [1,1]]), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b831a",
   "metadata": {},
   "source": [
    "The next block defines several fitness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "986a754c-ae68-456e-a5ff-c6f694f05ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_fitness(correct, predict):\n",
    "    return max(np.sum(np.log(predict[range(predict.shape[0]), correct])) + predict.shape[0], 0)\n",
    "\n",
    "  # computes fitness based on xor of all binary sequences of a given length\n",
    "def xor_fitness(net, inputs, outputs, gradient = False):\n",
    "    predict = net.forward(inputs, gradient)\n",
    "    return cross_entropy_fitness(outputs, predict)\n",
    "\n",
    "def xor_all_fitness(net, inputs, outputs, gradient = False):\n",
    "    predict = net.forward(inputs, gradient)\n",
    "    return np.log(predict[range(predict.shape[0]), outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820705d5",
   "metadata": {},
   "source": [
    "In this section, we define crossover and mutation operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a71c31bb-4aa0-4682-932a-aa64c95a83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_minimax(net1, net2):\n",
    "    node_seq = net1.node_seq\n",
    "    activation = net1.activation\n",
    "    new_net1 = Network(node_seq, activation, Xavier = False)\n",
    "    new_net2 = Network(node_seq, activation, Xavier = False)\n",
    "    for idx in range(net1.num_layers): #perhaps random choice, instead of one net all minima and one net all maxima\n",
    "        new_net1.weight_mats[idx] = np.minimum(net1.weight_mats[idx], net2.weight_mats[idx])\n",
    "        new_net2.weight_mats[idx] = np.maximum(net1.weight_mats[idx], net2.weight_mats[idx])\n",
    "        new_net1.bias_vecs[idx] = np.minimum(net1.bias_vecs[idx], net2.bias_vecs[idx])\n",
    "        new_net2.bias_vecs[idx] = np.maximum(net1.bias_vecs[idx], net2.bias_vecs[idx])\n",
    "    return new_net1, new_net2\n",
    "    \n",
    "def crossover_layer(net1, net2):\n",
    "    node_seq = net1.node_seq\n",
    "    activation = net1.activation\n",
    "    new_net1 = Network(node_seq, activation, Xavier = False)\n",
    "    new_net2 = Network(node_seq, activation, Xavier = False)\n",
    "    select_layers = np.random.uniform(size = net1.num_layers)\n",
    "    for idx in range(net1.num_layers): \n",
    "        if select_layers[idx] < 0.5:\n",
    "            new_net1.weight_mats[idx] = net1.weight_mats[idx]\n",
    "            new_net2.weight_mats[idx] = net2.weight_mats[idx]\n",
    "            new_net1.bias_vecs[idx] = net1.bias_vecs[idx]\n",
    "            new_net2.bias_vecs[idx] = net2.bias_vecs[idx]\n",
    "        else:\n",
    "            new_net1.weight_mats[idx] = net2.weight_mats[idx]\n",
    "            new_net2.weight_mats[idx] = net1.weight_mats[idx]\n",
    "            new_net1.bias_vecs[idx] = net2.bias_vecs[idx]\n",
    "            new_net2.bias_vecs[idx] = net1.bias_vecs[idx]\n",
    "    return new_net1, new_net2\n",
    "    \n",
    "def mut_layer(net, gradient = False):\n",
    "    mut_size = np.random.uniform()\n",
    "    select_layers = np.random.uniform(size = net.num_layers)\n",
    "    for idx in range(net.num_layers): \n",
    "        if select_layers[idx] < 0.5:\n",
    "            n_in = net.node_seq[idx]\n",
    "            n_out = net.node_seq[idx + 1]\n",
    "            bound = np.sqrt(6/(n_in + n_out)) * mut_size\n",
    "            if gradient:\n",
    "                net.weight_mats[idx] += np.random.uniform(-mut_size, mut_size, \\\n",
    "                     size = (n_in, n_out)) / np.sqrt(np.maximum(np.abs(net.weight_mats_gradient[idx]), 0.1))\n",
    "                net.bias_vecs[idx] += np.random.uniform(-mut_size, mut_size, \\\n",
    "                     size = n_out) /  np.sqrt(np.maximum(np.abs(net.bias_vecs_gradient[idx]), 0.1))\n",
    "            else:\n",
    "                bound = np.sqrt(6/(n_in + n_out)) * mut_size\n",
    "                net.weight_mats[idx] += np.random.uniform(-bound, bound, size = (n_in, n_out))\n",
    "                net.bias_vecs[idx] += np.random.uniform(-bound, bound, size = n_out)\n",
    "\n",
    "def mut_index(net, gradient = False):\n",
    "    mut_size = np.random.uniform()\n",
    "    idx = int(np.random.choice(net.num_layers, 1))\n",
    "    n_in = net.node_seq[idx]\n",
    "    n_out = net.node_seq[idx + 1]\n",
    "    idx2 = int(np.random.choice(n_in, 1))\n",
    "    idx3 = int(np.random.choice(n_out, 1))\n",
    "    if gradient:\n",
    "        net.weight_mats[idx][idx2][idx3] += np.random.uniform(-mut_size, mut_size, \\\n",
    "            size = 1) / np.sqrt(np.maximum(np.abs(net.weight_mats_gradient[idx][idx2][idx3]), 0.1))\n",
    "    else:\n",
    "        bound = np.sqrt(6/(n_in + n_out)) * mut_size\n",
    "        net.weight_mats[idx][idx2][idx3] += np.random.uniform(-bound, bound, size = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2108471",
   "metadata": {},
   "source": [
    "The class Genetic defines the neuroevolution algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa06f640-95ac-431a-b645-035c61b1ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genetic:\n",
    "    def __init__(self, pop_size, node_seq, activation_functions, fitness_function, \n",
    "                 inp, outp, mutation_functions, mutation_probabilities, \n",
    "                 crossover_functions, crossover_probabilities, elite, gradient = False,\n",
    "                 max_fitness = np.inf):\n",
    "        self.net_list = []\n",
    "        self.pop_size = pop_size\n",
    "        for idx in range(pop_size):\n",
    "            self.net_list.append(Network(node_seq, activation_functions))\n",
    "        \n",
    "        self.fitness_func = fitness_function\n",
    "        self.inp = inp\n",
    "        self.outp = outp\n",
    "        self.grad = gradient\n",
    "        self.mutation_func = mutation_functions\n",
    "        self.mutation_threshold = np.cumsum(mutation_probabilities)\n",
    "        self.crossover_func = crossover_functions\n",
    "        self.crossover_threshold = np.cumsum(crossover_probabilities)\n",
    "        self.elite = elite\n",
    "        self.current_best_fitness = 0\n",
    "        self.max_fitness = max_fitness\n",
    "        self.hist = []\n",
    "        \n",
    "    def next_generation(self):\n",
    "        if self.current_best_fitness + 0.001 > self.max_fitness:\n",
    "            pass # continuing to evolve (near-)optimal solutions can lead to instability\n",
    "        \n",
    "        new_net_idx = np.random.permutation(self.pop_size)\n",
    "        new_net_list = [deepcopy(self.net_list[idx]) for idx in new_net_idx]\n",
    "        \n",
    "        select_mutate = np.random.uniform(size=self.pop_size)\n",
    "        for idx in range(self.pop_size):\n",
    "            for mut_idx in range(len(self.mutation_func)):\n",
    "                  # select mutation mut_idx if self.mutation_threshold[mut_idx-1] <\n",
    "                  # select_mutate[idx] < self.mutation_threshold[mut_idx]\n",
    "                if select_mutate[idx] < self.mutation_threshold[mut_idx]:\n",
    "                    self.mutation_func[mut_idx](new_net_list[idx], self.grad)\n",
    "                    break \n",
    "                    \n",
    "        cross_net_idx = np.random.permutation(self.pop_size)\n",
    "        cross_net_list = [deepcopy(self.net_list[idx]) for idx in cross_net_idx]\n",
    "        select_cross = np.random.uniform(size = self.pop_size)\n",
    "        for idx in range(self.pop_size//2):\n",
    "            for cross_idx in range(len(self.crossover_func)):\n",
    "                if select_cross[idx] < self.crossover_threshold[cross_idx]:\n",
    "                    cross_net_list[2*idx], cross_net_list[2*idx + 1] =  \\\n",
    "                      self.crossover_func[cross_idx](cross_net_list[2*idx], \\\n",
    "                                                     cross_net_list[2*idx + 1])\n",
    "                    \n",
    "        new_net_list.extend(cross_net_list)\n",
    "        new_net_list.extend(self.net_list)\n",
    "        for net in new_net_list:\n",
    "            net.fitness = self.fitness_func(net, self.inp, self.outp, self.grad)\n",
    "        \n",
    "        new_net_list.sort(key = lambda x: -x.fitness)\n",
    "        fitnesses = [net.fitness for net in new_net_list]\n",
    "        probabilities = fitnesses / np.sum(fitnesses)\n",
    "        net_idx = np.random.choice(len(new_net_list), self.pop_size - self.elite, p = probabilities)\n",
    "        self.net_list = [new_net_list[idx] for idx in net_idx]\n",
    "        self.net_list.extend(new_net_list[:self.elite])\n",
    "\n",
    "        self.net_list.sort(key = lambda x: -x.fitness)\n",
    "        if self.net_list[0].fitness > 0.0001 + self.current_best_fitness:\n",
    "            self.current_best_fitness = self.net_list[0].fitness\n",
    "        self.hist.append(self.net_list[0].fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e0ab3",
   "metadata": {},
   "source": [
    "# Testing XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3d4e268-6e92-4743-abb5-073e74c70304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_lengths = [2, 4]\n",
    "all_hists = []\n",
    "for seq_len in seq_lengths:\n",
    "    inputs = np.array([[(num >> idx) % 2 for idx in range(seq_len)] for num in range(2**seq_len)])\n",
    "    outputs = np.array([sum(seq) % 2 for seq in inputs])\n",
    "\n",
    "\n",
    "    genetic_algo = Genetic(50, [seq_len, 20, 2], [ReLU, SoftMax], xor_fitness, \n",
    "                            inputs, outputs,\n",
    "                            [mut_layer, mut_index], [0.5, 0.5], \n",
    "                            [crossover_minimax, crossover_layer], [0.5, 0.5], 1, True, 2**seq_len)\n",
    "    for gen in range(1500): #was 1500\n",
    "        genetic_algo.next_generation()\n",
    "    opt_net = genetic_algo.net_list[0]\n",
    "    xor_all_fitness(opt_net, inputs, outputs)\n",
    "    fitnesses = genetic_algo.hist\n",
    "    all_hists.append(fitnesses)\n",
    "\n",
    "#opt_net.forward([[0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "824032cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "inputs = np.array([[(num >> idx) % 2 for idx in range(seq_len)] for num in range(2**seq_len)])\n",
    "outputs = np.array([sum(seq) % 2 for seq in inputs])\n",
    "\n",
    "genetic_algo = Genetic(50, [seq_len, 20, 2], [ReLU, SoftMax], xor_fitness, \n",
    "                        inputs, outputs,\n",
    "                        [mut_layer, mut_index], [0.5, 0.5], \n",
    "                        [crossover_minimax, crossover_layer], [0.5, 0.5], 1, True, 2**seq_len)\n",
    "for gen in range(150): #was 6000\n",
    "    genetic_algo.next_generation()\n",
    "opt_net = genetic_algo.net_list[0]\n",
    "xor_all_fitness(opt_net, inputs, outputs)\n",
    "fitnesses = genetic_algo.hist\n",
    "all_hists.append(fitnesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d69e1a4a-8a17-474d-befc-0bbc8b6da462",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3268/3266667985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_hists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_hists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Seq_len = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitness\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_lengths.append(5)\n",
    "for i in range(0, len(seq_lengths)):\n",
    "    plt.plot(range(0,len(all_hists[i])), all_hists[i], label = \"Seq_len = \" + str(seq_lengths[i]))\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance of the neuroevolution algorithm on different sequence lengths.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522fac8",
   "metadata": {},
   "source": [
    "# IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba02ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.33, random_state=42)\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_algo = Genetic(50, [4, 20, 3], [ReLU, SoftMax], xor_fitness, \n",
    "                        x_train, y_train,\n",
    "                        [mut_layer, mut_index], [0.5, 0.5], \n",
    "                        [crossover_minimax, crossover_layer], [0.5, 0.5], 1)\n",
    "for gen in range(200):\n",
    "    genetic_algo.next_generation()\n",
    "opt_net = genetic_algo.net_list[0]\n",
    "xor_all_fitness(opt_net, x_train, y_train)\n",
    "fitnesses = genetic_algo.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078c4bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(fitnesses)), fitnesses, label = \"IRIS\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance of the neuroevolution algorithm on iris dataset.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3328ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = opt_net.forward(x_test)\n",
    "predicted = [np.argmax(x) for x in predict]\n",
    "acc = metrics.accuracy_score(y_test, predicted)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7bc6d4",
   "metadata": {},
   "source": [
    "With about 10 generations, we found an accuracy of around 80%. When the number of generations is increased to 200, we can almost always reach an accuracy > 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95351db1",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdad7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mnist.images[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.33, random_state=42)\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_algo = Genetic(50, [64, 20, 10], [ReLU, SoftMax], xor_fitness, \n",
    "                        x_train, y_train,\n",
    "                        [mut_layer, mut_index], [0.5, 0.5], \n",
    "                        [crossover_minimax, crossover_layer], [0.5, 0.5], 1)\n",
    "for gen in range(10):\n",
    "    genetic_algo.next_generation()\n",
    "opt_net = genetic_algo.net_list[0]\n",
    "xor_all_fitness(opt_net, x_train, y_train)\n",
    "fitnesses = genetic_algo.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(fitnesses)), fitnesses, label = \"IRIS\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance of the neuroevolution algorithm on iris dataset.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = opt_net.forward(x_test)\n",
    "predicted = [np.argmax(x) for x in predict]\n",
    "acc = metrics.accuracy_score(y_test, predicted)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

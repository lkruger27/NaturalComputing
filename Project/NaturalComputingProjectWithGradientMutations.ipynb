{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb439d9",
   "metadata": {},
   "source": [
    "# Project Natural Computing\n",
    "\n",
    "First we add some imports that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b361494-ef60-4587-bc91-de57be2a2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e09fd",
   "metadata": {},
   "source": [
    "Next, we define the activation functions. There is a choice between ReLU, Sigmoid and SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a96c5bd-54d9-47b9-a0ad-c3b764e2cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(mat, gradient = False):\n",
    "    if gradient:\n",
    "        return mat * (mat > 0), 1 * (mat > 0)\n",
    "    return mat * (mat > 0)\n",
    "\n",
    "def Sigmoid(mat, gradient = False):\n",
    "    sigm = 1/(1 + np.exp(-mat))\n",
    "    if gradient:\n",
    "        return sigm, sigm * (1 - sigm)\n",
    "    return sigm\n",
    "\n",
    "def SoftMax(mat, gradient = False):\n",
    "    exp_mat = np.exp(mat)\n",
    "    res_mat =  exp_mat/np.sum(exp_mat, axis = 1, keepdims = True)\n",
    "    if gradient:\n",
    "        return res_mat, res_mat * (1 - res_mat)\n",
    "    return res_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a58efc",
   "metadata": {},
   "source": [
    "Next, we have a network class which contains the number of layer, activation function, weights, biases and current fitness.\n",
    "\n",
    "The forward function pushes the samples through the current network and returns the return values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c467a5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.25283717, 0.74716283],\n",
       "       [0.32648448, 0.67351552],\n",
       "       [0.14092044, 0.85907956]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network:\n",
    "    def __init__(self, node_seq, activation_functions, Xavier = True):\n",
    "        self.node_seq = node_seq\n",
    "        self.num_layers = len(node_seq) - 1\n",
    "        self.activation = activation_functions\n",
    "        self.weight_mats = []\n",
    "        self.bias_vecs = []\n",
    "        self.fitness = 0\n",
    "        self.weight_mats_gradient = []\n",
    "        self.bias_vecs_gradient = []\n",
    "        for idx in range(self.num_layers):\n",
    "            n_in = node_seq[idx]\n",
    "            n_out = node_seq[idx + 1]\n",
    "              # use Xavier initialization\n",
    "            bound = np.sqrt(6/(n_in + n_out))\n",
    "            if Xavier:\n",
    "                self.weight_mats.append(np.random.uniform(-bound, bound, size = (n_in, n_out)))\n",
    "            else: \n",
    "                self.weight_mats.append(np.zeros((n_in, n_out)))\n",
    "            self.bias_vecs.append(np.zeros(n_out))\n",
    "            self.weight_mats_gradient.append(np.zeros((n_in, n_out)))\n",
    "            self.bias_vecs_gradient.append(np.zeros(n_out))\n",
    "            \n",
    "            \n",
    "    def forward(self, samples, gradient = False):\n",
    "        # note: give inputs in the form (samples, features)\n",
    "        if not gradient:\n",
    "            for idx in range(self.num_layers):\n",
    "                samples = self.activation[idx](samples @ self.weight_mats[idx] + self.bias_vecs[idx])\n",
    "            return samples\n",
    "    \n",
    "        n_samples = samples.shape[0]\n",
    "        sample_list = [samples]\n",
    "        current_sample = samples\n",
    "        gradient_list = []\n",
    "        layer_gradient = []\n",
    "          \n",
    "          # forward step\n",
    "        for idx in range(self.num_layers):\n",
    "            current_sample, current_gradient = self.activation[idx](current_sample @ \n",
    "                     self.weight_mats[idx] + self.bias_vecs[idx], gradient = True)\n",
    "            gradient_list.append(current_gradient)\n",
    "            sample_list.append(current_sample)\n",
    "            n_in = self.node_seq[idx]\n",
    "            n_out = self.node_seq[idx + 1]\n",
    "            layer_gradient.append(np.zeros((n_samples, n_in)))\n",
    "        \n",
    "          # backward step\n",
    "        layer_gradient.append(2*sample_list[self.num_layers])\n",
    "        for idx in range(self.num_layers - 1, -1, -1):\n",
    "            self.weight_mats_gradient[idx] = sample_list[idx].T @ layer_gradient[idx + 1]\n",
    "            self.bias_vecs_gradient[idx] = np.ones(n_samples).T @ layer_gradient[idx + 1]\n",
    "            layer_gradient[idx] = (layer_gradient[idx + 1] * gradient_list[idx]) @ self.weight_mats[idx].T \n",
    "        \n",
    "        return current_sample\n",
    "        \n",
    "        \n",
    "net = Network([2,2,2], [ReLU, SoftMax])\n",
    "net.forward(np.array([[0,0], [0,1], [1,0], [1,1]]), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b831a",
   "metadata": {},
   "source": [
    "The next block defines several fitness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986a754c-ae68-456e-a5ff-c6f694f05ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_fitness(correct, predict):\n",
    "    return max(np.sum(np.log(predict[range(predict.shape[0]), correct])) + predict.shape[0], 0)\n",
    "\n",
    "  # computes fitness based on xor of all binary sequences of a given length\n",
    "def xor_fitness(net, inputs, outputs, gradient = False):\n",
    "    predict = net.forward(inputs, gradient)\n",
    "    return cross_entropy_fitness(outputs, predict)\n",
    "\n",
    "def xor_all_fitness(net, inputs, outputs, gradient = False):\n",
    "    predict = net.forward(inputs, gradient)\n",
    "    return np.log(predict[range(predict.shape[0]), outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820705d5",
   "metadata": {},
   "source": [
    "In this section, we define crossover and mutation operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a71c31bb-4aa0-4682-932a-aa64c95a83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_minimax(net1, net2):\n",
    "    node_seq = net1.node_seq\n",
    "    activation = net1.activation\n",
    "    new_net1 = Network(node_seq, activation, Xavier = False)\n",
    "    new_net2 = Network(node_seq, activation, Xavier = False)\n",
    "    for idx in range(net1.num_layers): #perhaps random choice, instead of one net all minima and one net all maxima\n",
    "        new_net1.weight_mats[idx] = np.minimum(net1.weight_mats[idx], net2.weight_mats[idx])\n",
    "        new_net2.weight_mats[idx] = np.maximum(net1.weight_mats[idx], net2.weight_mats[idx])\n",
    "        new_net1.bias_vecs[idx] = np.minimum(net1.bias_vecs[idx], net2.bias_vecs[idx])\n",
    "        new_net2.bias_vecs[idx] = np.maximum(net1.bias_vecs[idx], net2.bias_vecs[idx])\n",
    "    return new_net1, new_net2\n",
    "    \n",
    "def crossover_layer(net1, net2):\n",
    "    node_seq = net1.node_seq\n",
    "    activation = net1.activation\n",
    "    new_net1 = Network(node_seq, activation, Xavier = False)\n",
    "    new_net2 = Network(node_seq, activation, Xavier = False)\n",
    "    select_layers = np.random.uniform(size = net1.num_layers)\n",
    "    for idx in range(net1.num_layers): \n",
    "        if select_layers[idx] < 0.5:\n",
    "            new_net1.weight_mats[idx] = net1.weight_mats[idx]\n",
    "            new_net2.weight_mats[idx] = net2.weight_mats[idx]\n",
    "            new_net1.bias_vecs[idx] = net1.bias_vecs[idx]\n",
    "            new_net2.bias_vecs[idx] = net2.bias_vecs[idx]\n",
    "        else:\n",
    "            new_net1.weight_mats[idx] = net2.weight_mats[idx]\n",
    "            new_net2.weight_mats[idx] = net1.weight_mats[idx]\n",
    "            new_net1.bias_vecs[idx] = net2.bias_vecs[idx]\n",
    "            new_net2.bias_vecs[idx] = net1.bias_vecs[idx]\n",
    "    return new_net1, new_net2\n",
    "    \n",
    "def mut_layer(net, gradient = False):\n",
    "    mut_size = np.random.uniform()\n",
    "    select_layers = np.random.uniform(size = net.num_layers)\n",
    "    for idx in range(net.num_layers): \n",
    "        if select_layers[idx] < 0.5:\n",
    "            n_in = net.node_seq[idx]\n",
    "            n_out = net.node_seq[idx + 1]\n",
    "            bound = np.sqrt(6/(n_in + n_out)) * mut_size\n",
    "            if gradient:\n",
    "                net.weight_mats[idx] += np.random.uniform(-mut_size, mut_size, \\\n",
    "                     size = (n_in, n_out)) / np.sqrt(np.maximum(np.abs(net.weight_mats_gradient[idx]), 0.01))\n",
    "                net.bias_vecs[idx] += np.random.uniform(-mut_size, mut_size, \\\n",
    "                     size = n_out) /  np.sqrt(np.maximum(np.abs(net.bias_vecs_gradient[idx]), 0.01))\n",
    "            else:\n",
    "                bound = np.sqrt(6/(n_in + n_out)) * mut_size\n",
    "                net.weight_mats[idx] += np.random.uniform(-bound, bound, size = (n_in, n_out))\n",
    "                net.bias_vecs[idx] += np.random.uniform(-bound, bound, size = n_out)\n",
    "\n",
    "def mut_index(net, gradient = False):\n",
    "    mut_size = np.random.uniform()\n",
    "    idx = int(np.random.choice(net.num_layers, 1))\n",
    "    n_in = net.node_seq[idx]\n",
    "    n_out = net.node_seq[idx + 1]\n",
    "    idx2 = int(np.random.choice(n_in, 1))\n",
    "    idx3 = int(np.random.choice(n_out, 1))\n",
    "    if gradient:\n",
    "        net.weight_mats[idx][idx2][idx3] += np.random.uniform(-mut_size, mut_size, \\\n",
    "            size = 1) / np.sqrt(np.maximum(np.abs(net.weight_mats_gradient[idx][idx2][idx3]), 0.01))\n",
    "    else:\n",
    "        bound = np.sqrt(6/(n_in + n_out)) * mut_size\n",
    "        net.weight_mats[idx][idx2][idx3] += np.random.uniform(-bound, bound, size = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2108471",
   "metadata": {},
   "source": [
    "The class Genetic defines the neuroevolution algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa06f640-95ac-431a-b645-035c61b1ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genetic:\n",
    "    def __init__(self, pop_size, node_seq, activation_functions, fitness_function, \n",
    "                 inp, outp, mutation_functions, mutation_probabilities, \n",
    "                 crossover_functions, crossover_probabilities, elite, gradient = False):\n",
    "        self.net_list = []\n",
    "        self.pop_size = pop_size\n",
    "        for idx in range(pop_size):\n",
    "            self.net_list.append(Network(node_seq, activation_functions))\n",
    "        \n",
    "        self.fitness_func = fitness_function\n",
    "        self.inp = inp\n",
    "        self.outp = outp\n",
    "        self.grad = gradient\n",
    "        self.mutation_func = mutation_functions\n",
    "        self.mutation_threshold = np.cumsum(mutation_probabilities)\n",
    "        self.crossover_func = crossover_functions\n",
    "        self.crossover_threshold = np.cumsum(crossover_probabilities)\n",
    "        self.elite = elite\n",
    "        self.current_best_fitness = 0\n",
    "        self.hist = []\n",
    "        \n",
    "    def next_generation(self):\n",
    "        new_net_idx = np.random.permutation(self.pop_size)\n",
    "        new_net_list = [deepcopy(self.net_list[idx]) for idx in new_net_idx]\n",
    "        \n",
    "        select_mutate = np.random.uniform(size=self.pop_size)\n",
    "        for idx in range(self.pop_size):\n",
    "            for mut_idx in range(len(self.mutation_func)):\n",
    "                  # select mutation mut_idx if self.mutation_threshold[mut_idx-1] <\n",
    "                  # select_mutate[idx] < self.mutation_threshold[mut_idx]\n",
    "                if select_mutate[idx] < self.mutation_threshold[mut_idx]:\n",
    "                    self.mutation_func[mut_idx](new_net_list[idx], self.grad)\n",
    "                    break \n",
    "                    \n",
    "        cross_net_idx = np.random.permutation(self.pop_size)\n",
    "        cross_net_list = [deepcopy(self.net_list[idx]) for idx in cross_net_idx]\n",
    "        select_cross = np.random.uniform(size = self.pop_size)\n",
    "        for idx in range(self.pop_size//2):\n",
    "            for cross_idx in range(len(self.crossover_func)):\n",
    "                if select_cross[idx] < self.crossover_threshold[cross_idx]:\n",
    "                    cross_net_list[2*idx], cross_net_list[2*idx + 1] =  \\\n",
    "                      self.crossover_func[cross_idx](cross_net_list[2*idx], \\\n",
    "                                                     cross_net_list[2*idx + 1])\n",
    "                    \n",
    "        new_net_list.extend(cross_net_list)\n",
    "        new_net_list.extend(self.net_list)\n",
    "        for net in new_net_list:\n",
    "            net.fitness = self.fitness_func(net, self.inp, self.outp, self.grad)\n",
    "        \n",
    "        new_net_list.sort(key = lambda x: -x.fitness)\n",
    "        fitnesses = [net.fitness for net in new_net_list]\n",
    "        probabilities = fitnesses / np.sum(fitnesses)\n",
    "        net_idx = np.random.choice(len(new_net_list), self.pop_size - self.elite, p = probabilities)\n",
    "        self.net_list = [new_net_list[idx] for idx in net_idx]\n",
    "        self.net_list.extend(new_net_list[:self.elite])\n",
    "\n",
    "        self.net_list.sort(key = lambda x: -x.fitness)\n",
    "        if self.net_list[0].fitness > 0.0001 + self.current_best_fitness:\n",
    "            self.current_best_fitness = self.net_list[0].fitness\n",
    "        self.hist.append(self.net_list[0].fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e0ab3",
   "metadata": {},
   "source": [
    "# Testing XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3d4e268-6e92-4743-abb5-073e74c70304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_lengths = [2, 4]\n",
    "all_hists = []\n",
    "for seq_len in seq_lengths:\n",
    "    inputs = np.array([[(num >> idx) % 2 for idx in range(seq_len)] for num in range(2**seq_len)])\n",
    "    outputs = np.array([sum(seq) % 2 for seq in inputs])\n",
    "\n",
    "\n",
    "    genetic_algo = Genetic(50, [seq_len, 20, 2], [ReLU, SoftMax], xor_fitness, \n",
    "                            inputs, outputs,\n",
    "                            [mut_layer, mut_index], [0.5, 0.5], \n",
    "                            [crossover_minimax, crossover_layer], [0.5, 0.5], 1, True)\n",
    "    for gen in range(150): #was 1500\n",
    "        genetic_algo.next_generation()\n",
    "    opt_net = genetic_algo.net_list[0]\n",
    "    xor_all_fitness(opt_net, inputs, outputs)\n",
    "    fitnesses = genetic_algo.hist\n",
    "    all_hists.append(fitnesses)\n",
    "\n",
    "#opt_net.forward([[0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824032cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "inputs = np.array([[(num >> idx) % 2 for idx in range(seq_len)] for num in range(2**seq_len)])\n",
    "outputs = np.array([sum(seq) % 2 for seq in inputs])\n",
    "\n",
    "genetic_algo = Genetic(50, [seq_len, 20, 2], [ReLU, SoftMax], xor_fitness, \n",
    "                        inputs, outputs,\n",
    "                        [mut_layer, mut_index], [0.5, 0.5], \n",
    "                        [crossover_minimax, crossover_layer], [0.5, 0.5], 1, True)\n",
    "for gen in range(150): #was 6000\n",
    "    genetic_algo.next_generation()\n",
    "opt_net = genetic_algo.net_list[0]\n",
    "xor_all_fitness(opt_net, inputs, outputs)\n",
    "fitnesses = genetic_algo.hist\n",
    "all_hists.append(fitnesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e1a4a-8a17-474d-befc-0bbc8b6da462",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths.append(5)\n",
    "for i in range(0, len(seq_lengths)):\n",
    "    plt.plot(range(0,len(all_hists[i])), all_hists[i], label = \"Seq_len = \" + str(seq_lengths[i]))\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance of the neuroevolution algorithm on different sequence lengths.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522fac8",
   "metadata": {},
   "source": [
    "# IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba02ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.33, random_state=42)\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_algo = Genetic(50, [4, 20, 3], [ReLU, SoftMax], xor_fitness, \n",
    "                        x_train, y_train,\n",
    "                        [mut_layer, mut_index], [0.5, 0.5], \n",
    "                        [crossover_minimax, crossover_layer], [0.5, 0.5], 1)\n",
    "for gen in range(200):\n",
    "    genetic_algo.next_generation()\n",
    "opt_net = genetic_algo.net_list[0]\n",
    "xor_all_fitness(opt_net, x_train, y_train)\n",
    "fitnesses = genetic_algo.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078c4bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(fitnesses)), fitnesses, label = \"IRIS\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance of the neuroevolution algorithm on iris dataset.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3328ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = opt_net.forward(x_test)\n",
    "predicted = [np.argmax(x) for x in predict]\n",
    "acc = metrics.accuracy_score(y_test, predicted)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7bc6d4",
   "metadata": {},
   "source": [
    "With about 10 generations, we found an accuracy of around 80%. When the number of generations is increased to 200, we can almost always reach an accuracy > 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95351db1",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdad7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mnist.images[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.33, random_state=42)\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_algo = Genetic(50, [64, 20, 10], [ReLU, SoftMax], xor_fitness, \n",
    "                        x_train, y_train,\n",
    "                        [mut_layer, mut_index], [0.5, 0.5], \n",
    "                        [crossover_minimax, crossover_layer], [0.5, 0.5], 1)\n",
    "for gen in range(10):\n",
    "    genetic_algo.next_generation()\n",
    "opt_net = genetic_algo.net_list[0]\n",
    "xor_all_fitness(opt_net, x_train, y_train)\n",
    "fitnesses = genetic_algo.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(fitnesses)), fitnesses, label = \"IRIS\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance of the neuroevolution algorithm on iris dataset.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = opt_net.forward(x_test)\n",
    "predicted = [np.argmax(x) for x in predict]\n",
    "acc = metrics.accuracy_score(y_test, predicted)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
